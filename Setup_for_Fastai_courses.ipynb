{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Setup for Fastai courses.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/philrennie/fastai_pdlfc/blob/master/Setup_for_Fastai_courses.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "nUqh-hgo1Ap7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Put these at the top of every notebook, to get automatic reloading and inline plotting\n",
        "%reload_ext autoreload\n",
        "%autoreload 2\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SCixuXPg0_9A",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#Lesson 1\n"
      ]
    },
    {
      "metadata": {
        "id": "7I-mpi8E0-Uh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f3c01e13-814f-4ceb-8fba-2786dc2e049a"
      },
      "cell_type": "code",
      "source": [
        "!ls data/dogscats/"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "models\tsample\ttest1  train  valid\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "IjjhYKy-g4t-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We're going to try to set things up to do the fast.ai courses. Taking reference from https://github.com/corykendrick/fastai_in_colab/blob/master/Using_Google_Colab_for_Fastai.ipynb\n",
        "\n",
        "Make sure we're on Python 3\n"
      ]
    },
    {
      "metadata": {
        "id": "APYXexVPg0xh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bf71fd29-67ff-419c-af76-005e4f16ab27"
      },
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.version"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'3.6.3 (default, Oct  3 2017, 21:45:48) \\n[GCC 7.2.0]'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "metadata": {
        "id": "3wo3jGHYhaSq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now we need to pull in the fastai libraries. This might take a while."
      ]
    },
    {
      "metadata": {
        "id": "sDyLVH-chgM5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#install fastai\n",
        "!pip3 install fastai"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XIYxlljKitgI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Import all the libraries"
      ]
    },
    {
      "metadata": {
        "id": "wT9S_UyLizQf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# This file contains all the main external libs we'll use\n",
        "from fastai.imports import *"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tYiVxZCGi3S9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from fastai.transforms import *\n",
        "from fastai.conv_learner import *\n",
        "from fastai.model import *\n",
        "from fastai.dataset import *\n",
        "from fastai.sgdr import *\n",
        "from fastai.plots import *"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tPgeErddiKXX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "Now check that we're on a GPU instance. Both the following commands should return true"
      ]
    },
    {
      "metadata": {
        "id": "VOEnhevwiTG_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "39482ffc-aa7e-4e26-a797-887022946b12"
      },
      "cell_type": "code",
      "source": [
        "torch.cuda.is_available()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "metadata": {
        "id": "_3rSLPv6rVsn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bbaec09b-b69e-4e6d-8166-50fcb5d03f15"
      },
      "cell_type": "code",
      "source": [
        "torch.backends.cudnn.enabled"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "metadata": {
        "id": "Yx3xGR0mjFmJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#Check how much GPU is currently available"
      ]
    },
    {
      "metadata": {
        "id": "o9QUHwQOjK0A",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "b4992617-cc98-4864-b2de-10056599c231"
      },
      "cell_type": "code",
      "source": [
        "# memory footprint support libraries/code\n",
        "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
        "!pip install gputil\n",
        "!pip install psutil\n",
        "!pip install humanize\n",
        "import psutil\n",
        "import humanize\n",
        "import os\n",
        "import GPUtil as GPU\n",
        "GPUs = GPU.getGPUs()\n",
        "# XXX: only one GPU on Colab and isnâ€™t guaranteed\n",
        "gpu = GPUs[0]\n",
        "def printm():\n",
        " process = psutil.Process(os.getpid())\n",
        " print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n",
        " print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
        "printm()"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gputil in /usr/local/lib/python3.6/dist-packages (1.3.0)\r\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from gputil) (1.14.5)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.6/dist-packages (5.4.7)\n",
            "Requirement already satisfied: humanize in /usr/local/lib/python3.6/dist-packages (0.5.1)\n",
            "Gen RAM Free: 11.6 GB  | Proc size: 3.9 GB\n",
            "GPU RAM Free: 10434MB | Used: 1005MB | Util   9% | Total 11439MB\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}